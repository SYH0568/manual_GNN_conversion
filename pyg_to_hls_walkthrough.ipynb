{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bc2776",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b384d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdel/IRIS_HEP/pyg_to_hls_dev/hls4ml/hls4ml/converters/__init__.py:31: UserWarning: WARNING: Tensorflow converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Tensorflow converter is not enabled!\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from hls4ml.utils.config import config_from_pyg_model\n",
    "from hls4ml.converters import convert_from_pyg_model\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# locals\n",
    "from utils.models.interaction_network_pyg import InteractionNetwork\n",
    "from model_wrappers import model_wrapper\n",
    "from utils.data.dataset_pyg import GraphDataset\n",
    "from utils.data.fix_graph_size import fix_graph_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb118bac",
   "metadata": {},
   "source": [
    "### PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24082fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1: RelationalModel(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=40, out_features=40, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=40, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "R1.layers: Sequential(\n",
      "  (0): Linear(in_features=10, out_features=40, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=40, out_features=4, bias=True)\n",
      ")\n",
      "R1.layers.0: Linear(in_features=10, out_features=40, bias=True)\n",
      "R1.layers.1: ReLU()\n",
      "R1.layers.2: Linear(in_features=40, out_features=40, bias=True)\n",
      "R1.layers.3: ReLU()\n",
      "R1.layers.4: Linear(in_features=40, out_features=4, bias=True)\n",
      "O: ObjectModel(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=7, out_features=40, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=40, out_features=40, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=40, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "O.layers: Sequential(\n",
      "  (0): Linear(in_features=7, out_features=40, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=40, out_features=3, bias=True)\n",
      ")\n",
      "O.layers.0: Linear(in_features=7, out_features=40, bias=True)\n",
      "O.layers.1: ReLU()\n",
      "O.layers.2: Linear(in_features=40, out_features=40, bias=True)\n",
      "O.layers.3: ReLU()\n",
      "O.layers.4: Linear(in_features=40, out_features=3, bias=True)\n",
      "R2: RelationalModel(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=40, out_features=40, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=40, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "R2.layers: Sequential(\n",
      "  (0): Linear(in_features=10, out_features=40, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "R2.layers.0: Linear(in_features=10, out_features=40, bias=True)\n",
      "R2.layers.1: ReLU()\n",
      "R2.layers.2: Linear(in_features=40, out_features=40, bias=True)\n",
      "R2.layers.3: ReLU()\n",
      "R2.layers.4: Linear(in_features=40, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "torch_model = InteractionNetwork(aggr=\"add\", flow=\"source_to_target\", hidden_size=40)\n",
    "torch_model_dict = torch.load(\"trained_models//IN_pyg_small_add_source_to_target_40_state_dict.pt\")\n",
    "torch_model.load_state_dict(torch_model_dict)\n",
    "\n",
    "for name, submodule in torch_model.named_modules():\n",
    "    if name != \"\":\n",
    "        print(f\"{name}: {submodule}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2293596d",
   "metadata": {},
   "source": [
    "We can see that this specific GNN is composed of 3 submodules:\n",
    "- The first submodule, \"R1\", is a \"RelationalModel\" a.k.a. an \"EdgeBlock\"\n",
    "- The second submodule, \"O\", is an \"ObjectModel\" a.k.a. a \"NodeBlock\"\n",
    "- The third submodule, \"R2\" is another \"RelationalModel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49e754",
   "metadata": {},
   "source": [
    "### HLS Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e798bed7",
   "metadata": {},
   "source": [
    "hls4ml cannot infer the *order* in which these submodules are called within the pytorch model's \"forward()\" function. We have to manually define this information in the form of an ordered-dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b64da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward_dict: defines the order in which graph-blocks are called in the model's 'forward()' method\n",
    "forward_dict = OrderedDict()\n",
    "forward_dict[\"R1\"] = \"EdgeBlock\"\n",
    "forward_dict[\"O\"] = \"NodeBlock\"\n",
    "forward_dict[\"R2\"] = \"EdgeBlock\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "6dca8d9f",
   "metadata": {},
   "source": [
    "hls4ml creates a hardware implementation of the GNN, which can only be represented using fixed-size arrays. This restriction also applies to the inputs and outputs of the GNN, so we must define the size of the graphs that this hardware GNN can take as input**, again in the form of a dictionary. \n",
    "\n",
    "**Graphs of a different size can be padded or truncated to the appropriate size using the \"fix_graph_size\" function. In this notebook, padding/truncation is  done in the \"Data\" cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa5a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dims = {\n",
    "        \"n_node\": 28,\n",
    "        \"n_edge\": 37,\n",
    "        \"node_dim\": 3,\n",
    "        \"edge_dim\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "623f2192",
   "metadata": {},
   "source": [
    "Armed with our pytorch model and these two dictionaries**, we can create the HLS model. \n",
    "\n",
    "**If there is some activation function after the output of the final GNN-submodule, we also have to pass the type of this activation through the \"activate_final\" parameter of \"convert_from_pyg_model\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3c3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"test_GNN\"\n",
    "config = config_from_pyg_model(torch_model,\n",
    "                                   default_precision=\"ap_fixed<16,8>\",\n",
    "                                   default_index_precision='ap_uint<16>', \n",
    "                                   default_reuse_factor=1)\n",
    "hls_model = convert_from_pyg_model(torch_model,\n",
    "                                       n_edge=graph_dims['n_edge'],\n",
    "                                       n_node=graph_dims['n_node'],\n",
    "                                       edge_dim=graph_dims['edge_dim'],\n",
    "                                       node_dim=graph_dims['node_dim'],\n",
    "                                       forward_dictionary=forward_dict, \n",
    "                                       activate_final='sigmoid',\n",
    "                                       output_dir=output_dir,\n",
    "                                       hls_config=config)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c4b1ec2",
   "metadata": {},
   "source": [
    "The user can also define different fixed-point precision, integer/index precision, or reuse-factor parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59aa1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"test_GNN\"\n",
    "config = config_from_pyg_model(torch_model,\n",
    "                                   default_precision=\"ap_fixed<32,16>\",\n",
    "                                   default_index_precision='ap_uint<16>', \n",
    "                                   default_reuse_factor=8)\n",
    "hls_model = convert_from_pyg_model(torch_model,\n",
    "                                       n_edge=graph_dims['n_edge'],\n",
    "                                       n_node=graph_dims['n_node'],\n",
    "                                       edge_dim=graph_dims['edge_dim'],\n",
    "                                       node_dim=graph_dims['node_dim'],\n",
    "                                       forward_dictionary=forward_dict, \n",
    "                                       activate_final='sigmoid',\n",
    "                                       output_dir=output_dir,\n",
    "                                       hls_config=config)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5859accc",
   "metadata": {},
   "source": [
    "hls_model.compile() builds the C-function for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da705cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e678b04",
   "metadata": {},
   "source": [
    "# Evaluation and prediction: hls_model.predict(input)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e31a4c5a",
   "metadata": {},
   "source": [
    "If your model takes a non-singular input (e.g. node attributes, edge attributes, and an edge index), then you should pass it as a list (e.g. [node_attr, edge_attr, edge_index]). See the \"data_wrapper\" class, and note that the hls_model.predict() method is used on the data.hls_data attribute. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c3eaa",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4856a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_graphs: 2\n",
      "writing test bench data for 1st graph\n"
     ]
    }
   ],
   "source": [
    "class data_wrapper(object):\n",
    "    def __init__(self, node_attr, edge_attr, edge_index, target):\n",
    "        self.x = node_attr\n",
    "        self.edge_attr = edge_attr\n",
    "        self.edge_index = edge_index.transpose(0,1)\n",
    "\n",
    "        node_attr, edge_attr, edge_index = self.x.detach().cpu().numpy(), self.edge_attr.detach().cpu().numpy(), self.edge_index.transpose(0, 1).detach().cpu().numpy().astype(np.float32)\n",
    "        node_attr, edge_attr, edge_index = np.ascontiguousarray(node_attr), np.ascontiguousarray(edge_attr), np.ascontiguousarray(edge_index)\n",
    "        self.hls_data = [node_attr, edge_attr, edge_index]\n",
    "\n",
    "        self.target = target\n",
    "        self.np_target = np.reshape(target.detach().cpu().numpy(), newshape=(target.shape[0],))\n",
    "\n",
    "def load_graphs(graph_indir, graph_dims, n_graphs):\n",
    "    graph_files = np.array(os.listdir(graph_indir))\n",
    "    graph_files = np.array([os.path.join(graph_indir, graph_file)\n",
    "                            for graph_file in graph_files])\n",
    "    n_graphs_total = len(graph_files)\n",
    "    IDs = np.arange(n_graphs_total)\n",
    "    dataset = GraphDataset(graph_files=graph_files[IDs])\n",
    "\n",
    "    graphs = []\n",
    "    for data in dataset[:n_graphs]:\n",
    "        node_attr, edge_attr, edge_index, target, bad_graph = fix_graph_size(data.x, data.edge_attr, data.edge_index,\n",
    "                                                                             data.y,\n",
    "                                                                             n_node_max=graph_dims['n_node'],\n",
    "                                                                             n_edge_max=graph_dims['n_edge'])\n",
    "        if not bad_graph:\n",
    "            graphs.append(data_wrapper(node_attr, edge_attr, edge_index, target))\n",
    "    print(f\"n_graphs: {len(graphs)}\")\n",
    "\n",
    "    print(\"writing test bench data for 1st graph\")\n",
    "    data = graphs[0]\n",
    "    node_attr, edge_attr, edge_index = data.x.detach().cpu().numpy(), data.edge_attr.detach().cpu().numpy(), data.edge_index.transpose(\n",
    "        0, 1).detach().cpu().numpy().astype(np.int32)\n",
    "    os.makedirs('tb_data', exist_ok=True)\n",
    "    input_data = np.concatenate([node_attr.reshape(1, -1), edge_attr.reshape(1, -1), edge_index.reshape(1, -1)], axis=1)\n",
    "    np.savetxt('tb_data/input_data.dat', input_data, fmt='%f', delimiter=' ')\n",
    "\n",
    "    return graphs\n",
    "\n",
    "\n",
    "graph_indir = \"trackml_data/processed_plus_pyg_small\"\n",
    "graph_dims = {\n",
    "        \"n_node\": 28,\n",
    "        \"n_edge\": 37,\n",
    "        \"node_dim\": 3,\n",
    "        \"edge_dim\": 4\n",
    "    }\n",
    "graphs = load_graphs(graph_indir, graph_dims, n_graphs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374f8f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 7.784141189404181e-07\n"
     ]
    }
   ],
   "source": [
    "data = graphs[0]\n",
    "torch_pred = torch_model(data)\n",
    "hls_pred = hls_model.predict(data.hls_data)\n",
    "MSE = mean_squared_error(torch_pred.detach().cpu().numpy(), hls_pred)\n",
    "print(f\"MSE: {MSE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
